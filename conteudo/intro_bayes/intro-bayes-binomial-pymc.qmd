---
title: "Inferência Bayesiana Binomial com PyMC"  
subtitle: "Estimando $p$ pela modelagem probabilística"  
description: "Introdução à modelagem probabilística na abordagem bayesiana."
Categories: [
          "Inferência bayesiana",
          "Distribuição a priori",
          "Distribuição posterior",
          "Modelagem probabilística",
          "Modelo binomial"
        ]

image: "images/intro-bayes-binomial-pymc.png"  
execute:  
  echo: true  
  warning: false  
  include: true  
  message: false  

---

## Visão Geral

O **PyMC** é um pacote Python para modelagem estatística Bayesiana que utiliza métodos como **amostragem MCMC** (Markov Chain Monte Carlo) para estimar distribuições *a posteriori*. No caso de uma distribuição Binomial, podemos facilmente especificar uma **priori** Beta para o parâmetro $p$, observar dados (número de sucessos em $N$ ensaios) e obter a posteriori por meio de métodos de amostragem.

### Passo a Passo

1. **Definição do Modelo**  
   - Especificamos $p$ ~ Beta($\alpha_{\mathrm{prior}}$, $\beta_{\mathrm{prior}}$) como *a priori*.  
   - Modelamos os dados observados ($k$ sucessos em $N$ ensaios) via Binomial($N, p$).

2. **Amostragem MCMC**  
   - O PyMC utiliza, por padrão, o NUTS (No-U-Turn Sampler), uma variação de Hamiltonian Monte Carlo.  
   - Ajustamos parâmetros como `draws` (quantas amostras serão salvas após o período de warmup), `tune` (quantas iterações de aquecimento) e `chains` (quantas cadeias paralelas).

3. **Inspeção dos Resultados**  
   - `az.summary(trace)` exibe estatísticas como média, desvio-padrão, intervalos de credibilidade e $\hat{R}$ (verifica convergência).  
   - `az.plot_trace(trace)` plota a série temporal das amostras e o histograma.  
   - `az.plot_posterior(trace, var_names=["p"])` mostra a densidade *a posteriori*, intervalos de credibilidade e outras informações úteis.

## Exemplo de Código

```{python}
import pymc as pm
import arviz as az  # pacote complementar para análise/plot de resultados

# Parâmetros do experimento:
N = 10    # número total de ensaios
k = 6     # número de sucessos observados

# Parâmetros da priori Beta:
alpha_param = 2
beta_param = 2

# Define o modelo PyMC:
with pm.Model() as model:
    # 1) Distribuição a priori: Beta(alpha_param, beta_param)
    p = pm.Beta("p", alpha=alpha_param, beta=beta_param)
    
    # 2) Observações Binomiais
    # 'observed=k' indica que estamos informando dados observados
    obs = pm.Binomial("obs", n=N, p=p, observed=k)
    
    # 3) Amostragem MCMC
    # O PyMC usará, por padrão, o NUTS (No-U-Turn Sampler) para este tipo de modelo.
    trace = pm.sample(
        draws=2000,     # número de amostras pós-warmup
        tune=1000,      # número de iterações de warmup (ajuste)
        chains=2,       # número de cadeias em paralelo
        random_seed=42, # para reprodutibilidade
        target_accept=0.9
    )

# Podemos resumir e visualizar os resultados usando o ArviZ
print(az.summary(trace, var_names=["p"], kind="stats"))

# Plotando a posteriori e a evolução da cadeia
az.plot_trace(trace, var_names=["p"])
az.plot_posterior(trace, var_names=["p"], rope=[0.3, 0.7]);  # intervalos de relevância, se desejar
```

### Interpretação

- A **forma** e a **localização** da posteriori dependerão tanto dos dados observados ($k$, $N$) quanto dos parâmetros da *a priori* ($\alpha$, $\beta$).  
- Conforme $N$ aumenta, a verossimilhança passa a dominar o resultado, reduzindo o impacto de uma *a priori* moderada.  
- Se você alterar $\alpha_{\mathrm{prior}}$ e $\beta_{\mathrm{prior}}$, verá como suposições prévias mudam a forma inicial da posteriori, sobretudo em regimes de poucos dados.

---

## Exercício Sugerido

- **Varie** $N$ e $k$ para simular cenários distintos (poucos sucessos, muitos sucessos) e veja como a posteriori se adapta.  
- **Altere** $\alpha_{\mathrm{prior}}$ e $\beta_{\mathrm{prior}}$ (por exemplo, prior fortemente concentrada em 0.8) e observe se, com poucos dados, a posteriori permanece próxima da *a priori*.  
- Tente também usar `pm.sample_posterior_predictive(trace, ...)` para fazer predições sobre futuros ensaios (por exemplo, quantos sucessos esperar em novos $N_{\text{novos}}$ lançamentos).
