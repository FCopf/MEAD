{
  "hash": "55b2fdb039ad4b6cc8223db9c9874ba6",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"IntroduÃ§Ã£o Ã  InferÃªncia Bayesiana\"  \nsubtitle: \"De contagens a probabilidades\"  \ndescription: Texto adaptado do segundo capÃ­tulo (*Small Worlds and Large Worlds*) do livro **Statistical Rethinking â€“ A Bayesian Course with Examples in R and Stan** [@mcelreath2018statistical] e material disponÃ­vel em [**Statistical Rethinking course and book package**](https://github.com/rmcelreath/rethinking){target=\"_blank\"}  \nCategories: [\"Probabilidade\", \"InferÃªncia bayesiana\", \"teorema de Bayes\"]\n\nimage: \"images/intro-bayes-distr-prob.png\"  \nexecute:  \n  echo: false  \n  warning: false  \n  include: true  \n  message: false  \n\n---\n\n\n\n\n---\n\nVoltemos ao problema das bolinhas de gude. Temos uma caixa contendo quatro bolinhas, que podem ser azuis ou brancas. Sabemos que hÃ¡ exatamente quatro bolinhas, mas nÃ£o conhecemos a distribuiÃ§Ã£o entre as cores, pois podemos ver apenas uma bolinha por vez atravÃ©s de um orifÃ­cio. Para estimar quantas bolas de cada cor hÃ¡ na caixa, fazemos uma observaÃ§Ã£o, misturamos as bolinhas, fazemos outra observaÃ§Ã£o e assim por diante. Antes de realizarmos qualquer observaÃ§Ã£o, podemos listar cinco configuraÃ§Ãµes possÃ­veis para o conteÃºdo da caixa:\n\n1. [âšªâšªâšªâšª]  \n2. [ğŸ”µâšªâšªâšª]  \n3. [ğŸ”µğŸ”µâšªâšª]  \n4. [ğŸ”µğŸ”µğŸ”µâšª]  \n5. [ğŸ”µğŸ”µğŸ”µğŸ”µ]\n\nNosso objetivo Ã© *estimar o nÃºmero $N$ de bolas azuis*, o qual pode variar, neste exemplo, de 0 a 4. Como nÃ£o dispomos de conhecimento prÃ©vio sobre a composiÃ§Ã£o da caixa antes da primeira observaÃ§Ã£o, adotamos uma distribuiÃ§Ã£o *a priori* uniforme entre as hipÃ³teses. Assim, cada hipÃ³tese recebe uma probabilidade de $p = \\frac{1}{5}$.\n\n| **HipÃ³tese** | **N** | **Priori** |\n|:------------:|:-----:|:----------:|\n| [âšªâšªâšªâšª]   |  0    | $1/5$    |\n| [ğŸ”µâšªâšªâšª]   |  1    | $1/5$    |\n| [ğŸ”µğŸ”µâšªâšª]   |  2    | $1/5$    |\n| [ğŸ”µğŸ”µğŸ”µâšª]   |  3    | $1/5$    |\n| [ğŸ”µğŸ”µğŸ”µğŸ”µ]   |  4    | $1/5$    |\n\n: **DistribuiÃ§Ã£o de probabilidade *a priori* sobre o conteÃºdo da caixa** {#tbl-priori} \n\n---\n\n## DistribuiÃ§Ãµes *a priori*, *a posteriori* e *verossimilhanÃ§a*\n\nSuponha que realizamos trÃªs observaÃ§Ãµes da caixa e a sequÃªncia registrada seja [ğŸ”µ, âšª, ğŸ”µ] â€“ ou seja, obtivemos **N = 2** bolas azuis. Para atualizar nosso conhecimento sobre a composiÃ§Ã£o da caixa, combinamos nossa distribuiÃ§Ã£o *a priori* com a verossimilhanÃ§a de cada hipÃ³tese. A verossimilhanÃ§a Ã© calculada a partir da contagem do nÃºmero de maneiras em que cada hipÃ³tese pode gerar a sequÃªncia observada. Em seguida, aplicamos a regra de Bayes, que nos fornece a distribuiÃ§Ã£o *a posteriori* por meio da fÃ³rmula:\n\n$$\\text{Posterior}_i = \\frac{\\text{Priori}_i \\times P_i}{\\sum_{j} \\left(\\text{Priori}_j \\times P_j\\right)},$$\n\nonde $P_i$ representa, de forma proporcional, o nÃºmero de caminhos possÃ­veis para que a hipÃ³tese $i$ gere a sequÃªncia [ğŸ”µ, âšª, ğŸ”µ].\n\nNa tabela a seguir, apresentamos os cÃ¡lculos para cada hipÃ³tese:\n\n| **HipÃ³tese** | **N** | **Priori** | **Maneiras de produzir N = 2 [ğŸ”µâšªğŸ”µ]** | **Posterior** |\n|:------------:|:-----:|:----------:|:---------------------------------------:|:-------------:|\n| [âšªâšªâšªâšª]   |  0    | $1/5$    | $0 \\times 4 \\times 0 = 0$             | $\\dfrac{(1/5 \\times 0)}{\\sum (1/5 \\times \\text{NÂº de caminhos})} = 0$  |\n| [ğŸ”µâšªâšªâšª]   |  1    | $1/5$    | $1 \\times 3 \\times 1 = 3$             | $\\dfrac{(1/5 \\times 3)}{\\sum (1/5 \\times \\text{NÂº de caminhos})} = 0.15$  |\n| [ğŸ”µğŸ”µâšªâšª]   |  2    | $1/5$    | $2 \\times 2 \\times 2 = 8$             | $\\dfrac{(1/5 \\times 8)}{\\sum (1/5 \\times \\text{NÂº de caminhos})} = 0.40$  |\n| [ğŸ”µğŸ”µğŸ”µâšª]   |  3    | $1/5$    | $3 \\times 1 \\times 3 = 9$             | $\\dfrac{(1/5 \\times 9)}{\\sum (1/5 \\times \\text{NÂº de caminhos})} = 0.45$  |\n| [ğŸ”µğŸ”µğŸ”µğŸ”µ]   |  4    | $1/5$    | $4 \\times 0 \\times 4 = 0$             | $\\dfrac{(1/5 \\times 0)}{\\sum (1/5 \\times \\text{NÂº de caminhos})} = 0$  |\n\n: **Tabela: AtualizaÃ§Ã£o da distribuiÃ§Ã£o de probabilidade combinando a priori e verossimilhanÃ§a** {#tbl-posteriori} \n\nNa @tbl-posteriori, a coluna *â€œManeiras de produzir N = 2 [ğŸ”µâšªğŸ”µ]â€* indica o nÃºmero de caminhos possÃ­veis para que cada hipÃ³tese gere a sequÃªncia observada. Note que as hipÃ³teses [âšªâšªâšªâšª] e [ğŸ”µğŸ”µğŸ”µğŸ”µ] nÃ£o conseguem gerar a sequÃªncia (ou seja, possuem verossimilhanÃ§a zero). \n\n::: {#86b1fc72 .cell execution_count=1}\n\n::: {.cell-output .cell-output-display}\n![](intro-bayes-distr-prob_files/figure-html/cell-2-output-1.png){width=710 height=279}\n:::\n:::\n\n\nAo normalizarmos os produtos $\\text{Priori}_i \\times P_i$ â€” isto Ã©, dividindo cada um deles pelo somatÃ³rio $\\sum (1/5 \\times \\text{NÂº de caminhos})$ â€” obtemos a distribuiÃ§Ã£o **a posteriori**, que representa nosso conhecimento atualizado apÃ³s considerar as evidÃªncias observadas. O resultado final da inferÃªncia bayesiana Ã© a atribuiÃ§Ã£o de **probabilidades** â€” valores nÃ£o negativos, cuja soma Ã© igual a 1 â€” a cada uma das hipÃ³teses possÃ­veis sobre o conteÃºdo da caixa. Essas probabilidades expressam, de forma quantitativa, o quÃ£o plausÃ­vel Ã© cada hipÃ³tese Ã  luz dos dados disponÃ­veis.\n\n",
    "supporting": [
      "intro-bayes-distr-prob_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}