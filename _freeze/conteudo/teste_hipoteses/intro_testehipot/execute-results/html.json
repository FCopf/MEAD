{
  "hash": "0dc7c85599f663e532a6ecf887022eda",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Introdução ao Teste de Hipóteses\ndescription: \"Hipóteses nula/alternativa, erros do Tipo I/II, valor do p e nível de significância\"\nCategories: [\"Fundamentos Estatísticos\", \"Teste de Hipóteses\"]\n\nimage: \"images/intro_testehipot.jpg\"\nexecute:\n  echo: true\n  warning: false\n  include: true\n  message: false\n---\n\n\n\n\n:::{.callout-tip collapse=\"true\"}\n## Pacotes, funções e base de dados utilizadas\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n:::\n\n\n:::\n\nUm dos objetivos centrais em estatística é fazer inferências válidas para a **população** examinando as características de uma **amostra**. Considere as afirmações abaixo: \n\n> *A fragmentação de habitats reduz a diversidade de espécies*;\n\n> *Em níveis elevados de poluentes, a mortalidade de um determinado organismo aumenta*;\n\n> *A remoção da área de mangue implica na redução da captura de carbono*. \n\nTodas estas afirmações são na realidade **hipóteses**, sobre um ou mais parâmetros de uma população estatística que podem ser testadas por meio de experimentos adequados. A experimentação nos permite tirar conclusões sobre determitada hipótese com base na amostra. Mais especificamente, queremos saber se os dados em mãos nos permitem ou não refutar uma hipótese inicial. Portanto, se desejamos fazer uma inferência sobre um parâmetro da população estatística (ex.: sua média $\\mu$), devemos iniciar com uma afirmação sobre a posição deste parâmetro, que denominamos de **hipótese nula** ($H_0$). \n\n:::{.callout-note}\n\n# Um exemplo\n\n> Imagine que um modelo de climático estabeleça que a pluviosidade média entre junho e agosto nas cidades litorâneas do estado de São Paulo seja de $110$ mm/mês. \n\nUm cientista acredita que o modelo têm falhas e resolve tomar algumas observações sobre chuva mensal a fim de testar esta afirmação. Este cientista inicia formulando as **hipóteses estatísticas**, definindo o **limite de rejeição**, conduzindo o **experimento**, e por fim realizando o **teste de hipóteses**.\n\n\n\n1. **Hipoteses estatísticas**: inicialmente é necessário estabelecer o que chamamos de hipótese nula. Se uma análise estatística concluir que a hipótese nula deve ser **falsa**, então precisaremos ter me mãos uma hipótese **alternativa** ($H_a$). Assim, no caso de rejeição de $H_0$, passaremos a assumir $H_a$ como **verdadeira**. Neste exemplo teríamos:\n\n$H_0: \\mu = 110$ mm de chuva (HIPÓTESE NULA)\n\n$H_a: \\mu \\ne 110$ mm de chuva (HIPÓTESE ALTERNATIVA)\n\n2. **Limite de rejeição**: é o limite a partir do qual iremos conlcuir que $H_0$ é falsa. Este limite está baseado no que denominamos de **nível de significância** ($\\alpha$) sobre o qual iremos falar adiante.\n\n3. **Experimentação**: tomar amostras sobre o fenômeno em questão que nos permita tirar alguma conlusão sobre a veracidade de de $H_0$. Note que as hipóteses nula e alternativa se referem a predições sobre a posição da **média populaçional** $\\mu$, que é justamente a informação que não temos, mas sobre a qual queremos conhecer. Como não temos acesso à $\\mu$, nossa opção é tomar amostras do fenômeno (i.e. quantidade de chuva em diferentes localidades), calcular a média amostral $\\overline{X}$ e compará-la com a média populacional descrita em $H_0$. \n\n4. **Teste de hipóteses**: é o teste formal que nos permite dizer, com base nos resultados do experimento se há evidências suficiente para rejeitar $H_0$. Se não houver, concluímos que $H_0$ é verdadeira. Caso contrário assumimos $H_0$ como falsa e acitamos a hipótese alternativa $H_a$.\n\n:::\n\n## Probabilidade e teste de hipóteses\n\nA média $\\overline{X}$ de uma amostra será nossa melhor evidência a respeito de $\\mu$. Tendo este valor, podemos nos perguntar:\n\n> O valor obtido de $\\overline{X}$ é condizente com o esperado segundo $H_0$?\n\nCaso $\\overline{X}$ esteja **muito próximo** a $\\mu$, não há evidências para rejeitar $H_0$. Por outro lado, um valor de $\\overline{X}$ muito distante de $\\mu$ irá colocar em dúvida a afirmação estabelecida em $H_0$. O ponto relevante aqui é decidirmos *quão distante de $\\mu$ deve estar $\\overline{X}$ para que rejeitemos $H_0$?* Esta resposta poderá ser respondida **somente** com o auxílio de um modelo probabilístico aplicado ao experimento em questão. \n\nSeja $H_0$ verdadeira, é esperado que a probabilidade de $\\overline{X}$ estar próximo a $\\mu$ é alta. Portanto, uma pergunta melhor formulada seria:\n\n> Sendo $H_0$ **verdadeira**, qual é a probabilidade de que uma determinada média amostral $\\overline{X}$ esteja tão ou mais distante de $\\mu$ quanto o observado em nossa amostra particular?\n\n### Um modelo de distribuição das médias amostrais para testar $H_0$\n\nA pergunta feita acima é de natureza probabilística, de modo que para respondê-la iremos precisar estabelecer um **modelo probabilístico** para a distribuição das médias amostrais. De acordo com o que temos discutido até este ponto, **Teorema Central do Limite (TCL)** estabelece que a distribuição normal é um bom modelo neste situação.\n\nDesta forma, para um $H_0$ verdadeiro, seria esperado que a distribuição das médias amostrais resultantes de um procedimento experimental tivesse o formato de um distribuição normal, centrada em $110$ mm. Segundo o TCL, a distribuição seria centrada em $\\mu$ e o desvio padrão seria definido pelo **erro padrão da média**, isto é, $\\sigma_{\\overline{X}} = \\frac{\\sigma}{\\sqrt{n}}$.\n\nDigamos ainda que o modelo climático estabeleça que desvio padrão para a quantidade de chuva seja $\\sigma = 30$. Neste caso, o erro padrão seria de $\\sigma_{\\mu} = \\frac{30}{\\sqrt{n}}$.\n\nFeito isto, temos em mãos o **modelo probabilístico** que, aliado a uma amostra particular, nos permitirá concluir se há evidências para rejeitar $H_0$ em favor de $H_a$.\n\n### Definindo o limite de rejeição para $H_0$: nivel de significância $\\alpha$\n\nSegundo a distribuição normal, a probabilidade do valor observado $\\overline{X}$ estar **tão ou mais distante** de $\\mu$ na distribuição $Z$ é calculando por:\n\n$$z = \\frac{\\overline{X} - \\mu}{\\sigma_{\\overline{X}}}$$\n\nO valor de $z$ calculado é chamado de **estatitica do teste**. Com o uso da Tabela $Z$, esta estatística será utilizada para encontrar:\n\n$$P(Z \\ge z) = P(\\overline{X} \\ge \\mu)$$\nA probabilidade $P(Z \\ge z)$ é encontrada na **distribuição normal padronizada** em que $Z \\sim \\mathcal{N}(0,\\,\\frac{\\sigma}{\\sqrt{n}})$ e como nossa pergunta se refere à **distância** entre $\\overline{X}$ e $\\mu$, devemos encontar também $P(Z \\le -z)$, de modo que a probabilidade que nos interessa é denominada de **valor de p** de um teste de hipóteses:\n\n$$p = P(Z \\ge |z|)$$\n\nO valor de $p$ é a área destacada em vermelho da distribuição normal padronizada:\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Representação da área de rejeição na distribuição Z.](intro_testehipot_files/figure-html/fig-limite-rej-1.png){#fig-limite-rej width=768}\n:::\n:::\n\n\n\nA área destacada em vermelho diminui conforme $\\overline{X}$ se distancia de $\\mu$ e aumenta se $\\overline{X}$ está próximo a $\\mu$. \n\n:::{.callout-note}\n\n# O valor de p e nível de significância\n\nMede a probabilidade de encontrarmos $\\overline{X}$ tão ou mais distante de $\\mu$, **assumindo** que $H_0$ seja verdadeira. Se $p$ for muito pequeno, a probabilidade de que $\\overline{X}$ seja condizente com $H_0$ diminui. Neste caso dizemos que é **improvável** que $\\overline{X}$ seja proviniente de $H_0$, o que nos leva  levando a **rejeitar** a hipótese nula em favor de $H_a$. \n\nA decisão de rejeitar $H_0$ depende do **limite de rejeição** $\\alpha$, também chamado de **nivel crítico** ou **nível de significância**. A definir o valor de $\\alpha$, a conclusão de um teste estatístico se dá por (@fig-limite-rej-alfa):\n\n+ Se $p > \\alpha$ --> **ACEITAMOS $H_0$**, $\\overline{X}$ está próximo de $\\mu$ \n\n+ Se $p \\le \\alpha$ --> **REJEITAMOS $H_0$**, $\\overline{X}$ está distante de $\\mu$. A assumimos $H_a$ como verdadeira.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Efeito do nível de significancia sobre a área de rejeição em um teste de hipótese.](intro_testehipot_files/figure-html/fig-limite-rej-alfa-1.png){#fig-limite-rej-alfa width=768}\n:::\n:::\n\n\n\n:::\n\n## Exemplificando um teste de hipóteses: o teste $Z$\n\n::: {.callout-note}\n\n# Descrição do problema\n\nDigamos que o número de batimentos cardíacos por minuto de um adulto em repouso tenha média $\\mu = 65$ e desvio padrão $\\sigma = 9$. Você imagina que o sedentarismo altera o batimento médio de um adulto. \n\n:::\n\n1. **Hipóteses estatíticas**:\n\n$H_0: \\mu = 65$ batimentos por minuto\n\n$H_a: \\mu \\ne 65$ batimentos por minuto\n\n2. **Limite de rejeição**: determinamos o nível de significância ($\\alpha$) do teste como $\\alpha = 0,05$.\n\n> IMPORTANTE: O nível de significância $\\alpha$ deve ser determinado **antes** da tomada de dados.\n\n3. **Experimento**: selecionamos uma amostra **aleatória** selecionando *ao acaso* $n = 15$ pessoas de hábito sedentário e medimos seus batimentos cardíacos. Os resultados são:\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\nAmostra: 65, 73, 56, 71, 69, 69, 68, 59, 73, 68, 69, 64, 67, 64, 66\n\nque nos dá uma média amostral de:\n\n$\\overline{X} = \\frac{\\sum{X_i}}{n} = \\frac{65+73+56+71+69+69+68+59+73+68+69+64+67+64+66}{15} = 66.73$ batimentos por minuto;\n\ne um erro padrão de:\n\n$\\sigma_{\\mu} = \\frac{\\sigma}{\\sqrt{n}} = \\frac{9}{3.87} = 2.32$\n\n4. **Teste de hipóteses**: com estes resultados encontramos o valor correspondente de Z.\n\n$z = \\frac{\\overline{X} - \\mu}{\\sigma_{\\mu}} = \\frac{66.73 - 65}{2.32} = 0.75$\n\ne utilizando a <a href=\"https://github.com/FCopf/datasets/blob/main/Tabela_Z.pdf\" target=\"_blank\">Tabela Z</a> , encontramos a probabilidade de obtermos valores tão ou mais extremos que $-0.75$ e $+0.75$.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Área de rejeição para z = 0,75.](intro_testehipot_files/figure-html/fig-limite-tz-1.png){#fig-limite-tz width=768}\n:::\n:::\n\n\n\nCom isto, a probabilidade de encontarmos valores tão ou mais extermos que $\\overline{X} = 66.73$ foi calculada em $0.227 + 0.227 =$ **0.453**.\n\nNeste exemplo, a **estatística do teste** foi $z = 0.75$ o a probabilidade associada $p = 0.453$. \n\n::: {.callout-note}\n\n# Teste Z no R\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nX <- c(65, 73, 56, 71, 69, 69, 68, 59, 73, 68, 69, 64, 67, 64, 66)\nXm <- mean(X)\npnorm(q = Xm, mean = 65, sd = 9/sqrt(15), lower.tail = FALSE) * 2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4557231\n```\n\n\n:::\n:::\n\n\n\n:::\n\n## Tomada de decisão sobre $H_0$: nível de significância\n\nNo exemplo anterior, obtivemos $p =$ **0.453**. Isto significa que:\n\n> sendo $H_0$ **verdadeira**, existe uma probabilidade igual a $0.453$ de que a média de uma amostra com $n = 15$ esteja tão ou mais distante de $\\mu = 65$ como observado neste experimento. \n\nSe aceitarmos que esta probabilidade é **alta**, então não há motivo para buscar por outras explicações. Por outro lado, se concluirmos que esta probabilidade é **baixa**, estamos dizendo que resultado obtido é **improvável** segundo a hipótese nula. Neste caso, devemos recorrer à hipótese **alternativa** para explicar o fenômeno.\n\nPara decidir se a probabilidade obtida é alta ou baixa, devemos compará-la ao nível de significância $\\alpha$ pré-estabelecido. $H_0$ será aceita somente se a probabilidade encontrada for **maior** que $\\alpha$. Por outro lado, se nossa probabilidade for **menor ou igual** a $\\alpha$, considerarmos os resultados improváveis  segundo a hipótese nula e **rejeitamos** $H_0$ em favor de $H_a$. \n\nUm nível crítico comumente utilizado é $\\alpha = 0.05$. No exemplo acima a probabilidade foi de 0.453, um valor muito acima de $0.05$. Dizemos portanto, que a média amostral $\\overline{X}$ não está tão distante do $\\mu$ a ponto de rejeitarmos $H_0$. \n\n> Concluimos que, neste exemplo, $\\overline{X} = 66.73$ não nos fornece evidência suficiente para rejeitar $H_0$.\n\n## Erros de decisão em um teste de hipóteses\n\nA interpretação da probabilidade final esta associada à situação em que $H_0$ seja verdadeira.\n\nIsto nos leva perguntar: *o que esperar caso $H_0$ seja falsa*?\n\nComo não sabemos de fato, de $H_0$ é verdadeira ou não, a tomada de decisão sobre um resultado de um teste estatístico pode nos levar às seguintes situações:\n\n|                   | $H_0$ Verdadeira                       | $H_0$ Falsa\n| :---              | :------:                               | :------:\n| $H_0$ é rejeitada | $\\alpha$ ($\\textbf{Erro Tipo I}$)      | Decisão correta ($1-\\beta$)\n| $H_0$ é aceita    | Decisão correta ($1-\\alpha$)           | $\\beta$ ($\\textbf{Erro Tipo II}$)\n\n: Erros de decisão em um teste de hipótestes {#tbl-erros}\n\nA @tbl-erros nos mostra os tipos de erros aos quais estamos sujeitos ao realizar um teste de hipótese. Podemos rejeitar $H_0$, ainda que ela seja verdadeira. O nivel de significância adotado, estabele que a probabilidade disto acontecer é $\\alpha$. Se rejeitarmos $H_0$ quando ela é verdadeira, estaremos incorrendo em um erro de decisão que denominamos de **Erro Tipo I**. Consequentemente, temos uma probabilidade de $1 - \\alpha$ de aceitar corretamente $H_0$ quando ela é verdadeira. Estabelecer um $\\alpha = 0,05$ nos garante que iremos incorrer no erro do tipo I em somente $5\\%$ das vezes que o experimento for realizado.\n\nUm outra situação ocorre quando aceitamos erroneamente a hipótese nula que é **falsa**, incorrendo no **Erro Tipo II**. O erro do tipo II tem probabilidade $\\beta$ de acontecer. O complementar desta probabilidade ($1-\\beta$) é denominado de **Poder do Teste**. Um teste poderoso é portanto, aquele que tem elevada probabilidade de rejeitar $H_0$ quando ela é falsa.\n\nAs figuras abaixo representam as distribuições das médias amostrais e os erros do tipos I e II quando o $H_0$ é verdadeira ($\\mu_a = \\mu$) e quando $H_0$ é falsa ($\\mu_a > \\mu$).\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Relação entre o erro tipo I ($\\alpha$) e o erro tipos II ($\\beta$), ao aceitar ou rejeitar $H_0$.](intro_testehipot_files/figure-html/fig-alfa-beta-1.png){#fig-alfa-beta fig-align='center' width=768}\n:::\n:::\n\n\n\nIdealmente em um teste estatístico, seria interessante reduzir ao máximo os erros do tipo I e II. Ao reduzirmos o erro do tipo I, diminuindo $\\alpha$ teremos um teste mais rigoroso que raramente iria errar ao rejeitar um $H_0$ verdadeiro (Figura A). Entretanto, este teste também **raramente** iria rejeitar $H_0$ ainda que ele seja falso (Figura B). Consequentemente, ao diminuir o valor de $\\alpha$ ficamos menos propensos a cometer o erro do tipo I, porém **mais propensos** a incorrer no erro tipo II, isto é, não rejeitar uma $H_0$ falsa.\n\nDadas estas características, o único modo que reduzir os dois tipos de erros **simultaneamente** é aumentando o tamanho amostral $n$ pois, neste caso, reduzimos o erro padrão ($\\sigma_{\\overline{X}}$) e consequentemente a sobreposição entre as duas curvas acima.\n\n\n## Estabelecendo a hipótese alternativa: testes bilaterais *vs* unilaterais\n\nA hipótese alternativa estabelece nossa expectativa para a explicação dos resultados de um experimento no caso de $H_0$ ser falsa. Os testes que descrevemos acima são chamados **testes bilaterais ou bicaudais**. Isto significa que sendo $H_0$ falsa, podemos esperar que a média populacional esteja tanto acima quanto abaixo de $\\mu$. Existem situações, no entanto, para as quais já temos uma expectativa *a priori* com base no conhecimento prévio sobre o fenêmeno estudado.\n\nVoltemos ao exemplo sobre a frequência cardíaca. Sabemos que o sedentarismo, tende a elevar a frequência cardíaca em repouso. Deste modo, o problema poderia ser estabelecido da seguinte forma.\n\n::: {.callout-note}\n\n# Descrição do problema\n\nDigamos que o número de batimentos cardíacos por minuto de um adulto em repouso tenha média $\\mu = 65$ e desvio padrão $\\sigma = 9$. A literatura sugere que o **sedentarismo** aumenta o batimento médio de um adulto. \n\n:::\n\nO problema agora estabelece que no caso de rejeição de $H_0$, a frequência cardíaca deveia ser maior que 65 batimentos por minuto. Deste modo teremos como hipóteses estatísticas:\n\n1. **Hipóteses estatíticas**:\n\n$H_0: \\mu = 65$ batimentos por minuto\n\n$H_a: \\mu \\gt 65$ batimentos por minuto\n\nA mudança aqui está em $H_a$ que estabelece que na hipótese de rejeição de $H_0$, esperamos **somente** que a frequencia cardíaca aumente.\n\nEsta modificação na construção das hipóteses estatísticas tem implicação na definição do limite de rejeição.\n\n2. **Limite de rejeição**: se definimos $\\alpha = 0,05$, e $H_a: \\mu \\gt 65$, temos que a área de rejeição será expressa **acima** de 65 batimentos por minuto.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Área de rejeição em um teste unilateral com $\\alpha = 0,05$.](intro_testehipot_files/figure-html/fig-norm-unil-1.png){#fig-norm-unil width=768}\n:::\n:::\n\n\n\nNote portanto, que a diferença entre um teste bilateral e um teste unilateral está na definição dá área que expressa a zona de rejeição, $\\alpha$ para $H_0$. Nos teste bilaterais, a área de rejeição é distribuída acima e abaixo de $\\mu$ (@fig-limite-rej-alfa), enquanto nos teste unilaterais, a área estará toda acima ou abaixo de $\\mu$, a depender do que foi estabelecido em $H_a$ (@fig-norm-unil).\n\n\n___\n\n:::{.callout-note}\n# Vídeo-aulas\n\n\n\n{{< video https://youtu.be/LJJVcdAag24 >}}\n\n\n\n\n:::",
    "supporting": [
      "intro_testehipot_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}