{
  "hash": "cc57a00e3d60903413b227e3d7935375",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Modelo de Regressão Linear Bayesiana\"\nsubtitle: \"Modelando a relação entre Altura e Número do Calçado no PyMC\"\ndescription: \"Aplicação da regressão linear sob uma abordagem bayesiana, com foco na escolha de priores, checagens preditivas e inferência a posteriori.\"\nCategories: [\n        \"Inferência bayesiana\",\n        \"Regressão linear\",\n        \"Modelo normal\",\n        \"Distribuição a priori\",\n        \"Distribuição a posteriori\",\n        \"Checagem preditiva\",\n        \"PyMC\"\n        ]\nimage: \"images/regressao-linear-bayesiana.png\"\nexecute:\n    echo: true\n    warning: false\n    message: false\n---\n\n\n\n## Modelando Relações Lineares: a abordagem bayesiana\n\nNa inferência bayesiana, atualizamos nossas crenças sobre os parâmetros de um modelo combinando o **conhecimento prévio** (expresso pela distribuição *a priori*) com a **informação contida nos dados observados** (expressa pela **verossimilhança**) para obter a **distribuição *a posteriori***.\n\nDiferente da inferência frequentista, que busca estimativas pontuais e intervalos de confiança baseados na frequência de dados hipotéticos, a inferência bayesiana fornece uma **distribuição completa de probabilidade para os parâmetros**, refletindo explicitamente a incerteza sobre seus valores.\n\nNeste laboratório, aplicaremos a inferência bayesiana para modelar a relação entre duas variáveis contínuas: a **altura de indivíduos** e o **número do calçado** que utilizam. Intuitivamente, esperamos que haja uma relação positiva: pessoas mais altas tendem a usar números de calçado maiores. Para quantificar essa relação, utilizaremos um **modelo de regressão linear bayesiana**.\n\nVamos trabalhar com um conjunto de dados de altura e número de calçado de alunos, disponível no seguinte link: [`altura2022.csv`](https://github.com/FCopf/datasets/blob/main/altura2022.csv).\n\n---\n\n## O Modelo de Regressão Linear\n\nUm modelo de regressão linear simples postula que a variável resposta $y$ (por exemplo, a altura em cm) é uma **função linear da variável preditora $x$** (o número do calçado), mais um **termo de erro aleatório** $\\epsilon$. Este modelo é escrito como:\n\n$$\ny_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i\n$$\n\nOnde:\n\n- $y_i$ é a altura do *i-ésimo* indivíduo;\n- $x_i$ é o número do calçado do *i-ésimo* indivíduo;\n- $\\beta_0$ é o intercepto, representando a altura esperada quando o número do calçado é zero;\n- $\\beta_1$ é o coeficiente de regressão, representando o efeito de $x$ sobre o valor médio de $y$;\n- $\\epsilon_i$ é o termo de erro, assumido como $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma)$.\n\nEssa suposição implica que a variável resposta $y_i$, **condicionada** a $x_i$, $\\beta_0$, $\\beta_1$ e $\\sigma$, segue uma distribuição normal com média $\\beta_0 + \\beta_1 x_i$ e desvio padrão $\\sigma$:\n\n$$\ny_i \\sim \\mathcal{N}(\\beta_0 + \\beta_1 x_i, \\sigma)\n$$ {#eq-likelihood-normal-regression}\n\n---\n\n## As Prioris e o Modelo Generativo na Regressão Linear\n\nA equação @eq-likelihood-normal-regression especifica o **componente de verossimilhança** do modelo bayesiano. Para completar o modelo, precisamos definir as **distribuições *a priori*** para os parâmetros desconhecidos: $\\beta_0$, $\\beta_1$ e $\\sigma$.\n\nEssas distribuições a priori refletem o que sabemos (ou assumimos saber) sobre os parâmetros **antes de observar os dados**.\n\n\n::: {.callout-tip title=\"Atividade 1\"}\n\n1. Utilize o módulo scipy para simular a relação entre número do calçado e altura em centímetros. O objetivo desta simulação é avaliar queis seriam valores razoáveis para a escolha dos parâmetros $\\beta_0$, $\\beta_1$ e $\\sigma$\n\n::: {#95d1e90b .cell execution_count=2}\n``` {.python .cell-code}\n# Simular número do calçado (valores inteiros de 33 a 48, com 30 repetições por número)\nx_sim = np.repeat(np.arange(33, 49), 100)\n\n# Parâmetros hipotéticos para simulação\nbeta_0_mean = 60      # ESCOLHA a altura base (quando o número do calçado é zero)\nbeta_1_mean = 2.8      # ESCOLHA a taxa de aumento médio na altura para cada número a mais de calçado\nsigma_mean = 7         # ESCOLHA a variação individual na altura (desvio padrão dos erros)\n\n# Gerar alturas simuladas com erro normal\nepsilon = norm.rvs(loc=0, scale=sigma_mean, size=len(x_sim))\ny_sim = beta_0_mean + beta_1_mean * x_sim + epsilon\n\n# Plotar a simulação\nplt.close()\nplt.figure(figsize=(10, 6))\nplt.scatter(x_sim, y_sim, color='steelblue', alpha=0.6, label=\"Alturas simuladas\")\nplt.xlabel(\"Número do calçado\")\nplt.ylabel(\"Altura (cm)\")\nplt.title(\"Relação simulada entre número do calçado e altura\")\nplt.legend()\nplt.grid(True)\nplt.show()\n```\n:::\n\n\n2. Escolhidas as priores médias implemente o mdelo com PyMC\n\n::: {#d0d84614 .cell execution_count=3}\n``` {.python .cell-code}\n# Geração de valores simulados para a variável preditora (NUM_CALCADO)\ncalcado_sim = np.arange(33, 49)\n\nmean_prior_beta_0 = 60\nsd_prior_beta_0 = 5\n\nmean_prior_beta_1 = 2.8\nsd_prior_beta_1 = 0.1\n\nlmean_prior_sigma = 7\nlsd_prior_sigma = 0.4\n\nn_samples = 1000\nwith pm.Model() as modelo_regressao_linear:\n\n    # Priori para o intercepto\n    beta_0 = pm.Normal(\"beta_0\", mu=mean_prior_beta_0, sigma=sd_prior_beta_0)\n    \n    # Priori para o coeficiente angular\n    beta_1 = pm.Normal(\"beta_1\", mu=mean_prior_beta_1, sigma=sd_prior_beta_1)\n    \n    # Priori lognormal para o desvio padrão dos erros\n    sigma = pm.Lognormal(\"sigma\", mu=np.log(lmean_prior_sigma), sigma=lsd_prior_sigma)\n\n    # Equação da reta (modelo preditivo)\n    mu = beta_0 + beta_1 * calcado_sim\n\n    # Distribuição preditiva a priori\n    h_pred = pm.Normal(\"h_pred\", mu=mu, sigma=sigma, shape=len(calcado_sim))\n\n    # Amostragem da distribuição preditiva a priori\n    prior_predictive_samples = pm.sample_prior_predictive(samples=n_samples)\n```\n:::\n\n\n3. Checagem preditiva a priori\n\n::: {#fig-prior-parametros .cell execution_count=4}\n``` {.python .cell-code}\n# Extração das amostras\nbeta_0_prior = prior_predictive_samples.prior[\"beta_0\"].values.flatten()\nbeta_1_prior = prior_predictive_samples.prior[\"beta_1\"].values.flatten()\nsigma_prior = prior_predictive_samples.prior[\"sigma\"].values.flatten()\n\n# Plot dos histogramas\n# Plot dos histogramas e do gráfico de dispersão\nfig, axes = plt.subplots(2, 3, figsize=(12, 6))\n\n# Histograma do beta_0\naxes[0, 0].hist(beta_0_prior, bins=30, color='lightcoral', edgecolor='black')\naxes[0, 0].set_title(\"Intercepto: β₀\")\naxes[0, 0].set_xlabel(\"β₀\")\naxes[0, 0].set_ylabel(\"Frequência\")\n\n# Histograma do beta_1\naxes[0, 1].hist(beta_1_prior, bins=30, color='cornflowerblue', edgecolor='black')\naxes[0, 1].set_title(\"Inclinação: β₁\")\naxes[0, 1].set_xlabel(\"β₁\")\naxes[0, 1].set_ylabel(\"Frequência\")\n\n# Histograma de sigma\naxes[0, 2].hist(sigma_prior, bins=30, color='mediumseagreen', edgecolor='black')\naxes[0, 2].set_title(\"Desvio padrão: σ\")\naxes[0, 2].set_xlabel(\"σ\")\naxes[0, 2].set_ylabel(\"Frequência\")\n\n# Dispersão simulada\naxes[1, 1].scatter(x_sim, y_sim, color='steelblue', alpha=0.6, label=\"Alturas simuladas\")\naxes[1, 1].set_title(\"Relação simulada entre número do calçado e altura\")\naxes[1, 1].set_xlabel(\"Número do calçado\")\naxes[1, 1].set_ylabel(\"Altura (cm)\")\naxes[1, 1].legend()\naxes[1, 1].grid(True)\n\n# Desligar eixos não utilizados (1,0) e (1,2)\naxes[1, 0].axis(\"off\")\naxes[1, 2].axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n\n```\n:::\n\n\n:::\n\n",
    "supporting": [
      "regressao-linear-bayesiana_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}